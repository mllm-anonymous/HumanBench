<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Experiment Showcase</title>
    <link rel="stylesheet" href="main.css">
</head>
<body>
    <header>
        <h1>Clothing, Texture, Lighting: Unveiling Stereotypical Patterns in Multimodal Large Language Models</h1>
    </header>
    <main>
        <div class="container paragraph-container">
            <p>We present various experiments and results conducted for our research paper.</p>
        </div>
        <div class="container image-container">
            <p>The patterns existing in UTKFace [1] Dataset when working with LLaVA [2] and LLaVA-OneVision [3] Model and further 
                replicated using our synthetic datasets. Experiment 1 (Image 1) indicates the conenction between ethnic wear and the 
                interest attribute generated as "religion".</p>
            <img src="assets/religion-utk.jpg" alt="Experiment 1">
            <p>Experiment 2 (Image 2) indicates the conenction between mugshot-style images and occupation attribute generated 
                as "convict"/"criminal" and movie role attribute generated as "villian".</p>
            <img src="assets/convict-utk.jpg" alt="Experiment 2">
        </div>
        <div class="container image-container">
            <p>The images in the UTKFace dataset are created into embedding using the CLIP [4] Model and are plotted based on the 
                occupation attribute. This relation is plotted below as a scatterplot.</p>
            <img src="assets/scatter-occupation.jpg" alt="Experiment 3">
        </div>
        <div class="container list-container">
            <h3>References</h3>
            <ul>
                <li>[1] Song Yang Zhang, Zhifei and Hairong Qi. Age progression/regression by conditional adversarial autoencoder. In IEEE 
                    Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, 2017.</li>
                <li>[2] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. In Alice Oh, Tristan Naumann, 
                    Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing 
                    Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, 
                    LA, USA, December 10 - 16, 2023, 2023.</li>
                <li>[3] Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, and Chunyuan 
                    Li. Llava-onevision: Easy visual task transfer. CoRR,abs/2408.03326, 2024.</li>
                <li>Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, 
                    Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning transferable visual models from natural 
                    language supervision. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on 
                    Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, 
                    pages 8748â€“8763. PMLR, 2021.</li>
            </ul>
        </div>
    </main>
</body>
</html>
